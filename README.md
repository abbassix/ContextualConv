# ContextualConv

**ContextualConv** is a family of custom PyTorch convolutional layers (`ContextualConv1d`, `ContextualConv2d`, etc.) that extend standard convolutions with support for **global context conditioning**.

Instead of using built-in convolution operators, these layers apply convolution via **im2col + matrix multiplication**, while enabling **location-invariant modulation** via an optional context vector `c`.

---

## üîß Features

- ‚öôÔ∏è Drop-in replacement for `nn.Conv1d` and `nn.Conv2d` (with grouped conv support)
- üß† Context-aware: injects global information into every spatial or temporal location
- üß± Uses `unfold` (im2col) to compute convolution explicitly via matrix multiplication
- üì¶ Fully differentiable and autograd-compatible

---

## üì¶ Installation

Copy `contextual_conv.py` into your project directory and import the required layer:

```python
from contextual_conv import ContextualConv1d, ContextualConv2d
```

No external dependencies beyond PyTorch.

---

## üöÄ Usage
2D Example
```
import torch
from contextual_conv import ContextualConv2d

conv = ContextualConv2d(
    in_channels=16,
    out_channels=32,
    kernel_size=3,
    padding=1,
    c_dim=10  # context dimensionality
)

x = torch.randn(8, 16, 32, 32)       # input image tensor
c = torch.randn(8, 10)               # global context vector

out = conv(x, c)  # shape: (8, 32, 32, 32)

If you don‚Äôt need context, just omit it:

conv = ContextualConv2d(16, 32, kernel_size=3, padding=1)
out = conv(x)  # works without `c`
```

1D Example
```
from contextual_conv import ContextualConv1d

conv1d = ContextualConv1d(
    in_channels=16,
    out_channels=32,
    kernel_size=5,
    padding=2,
    c_dim=6
)

x = torch.randn(4, 16, 100)  # input time series
c = torch.randn(4, 6)        # context vector

out = conv1d(x, c)           # shape: (4, 32, 100)
```

You can omit the context vector `c` entirely if you don't need it:
```
conv = ContextualConv1d(16, 32, kernel_size=3, padding=1)
out = conv(x)  # still works without context
```

---

## üìê Context Vector

- The context tensor `c` can be of shape `(N, c_dim)` or `(N, 1, c_dim)`.

- It is *broadcasted* over all spatial positions and concatenated to the local input patch at each location.

- Learnable weights `c_weight` are applied to this context and used in the convolution computation.

---

## üîç When to Use

Use `ContextualConv` when you need:

- Feature maps influenced by external signals (e.g., class embeddings, latent codes).

- Global conditioning of convolutional outputs without spatial variation.

- Interpretable, customizable convolutional logic using explicit matrix ops.

---

## üìÑ License

GNU GPLv3 License

---

## ü§ù Contributing

Contributions are welcome! Feel free to:

- Add support for ContextualConv3d

- Improve speed via einsum or GPU-specific tricks

- Add performance benchmarks or gradient checks

Please open an issue or pull request.
---

## üß™ Tests

Unit tests are included in the tests/ directory. To verify the correctness of ContextualConv1d and ContextualConv2d, we compare their output against PyTorch‚Äôs built-in nn.Conv1d and nn.Conv2d using identical weights and no context.

### ‚úÖ Running the tests

Make sure you have pytest installed:
```
pip install pytest
```
Then run the tests:
```
pytest tests/
```
This will execute the test cases defined in tests/test_contextual_conv.py and confirm that the custom layers behave as expected.

---

## üì´ Contact

For questions or suggestions, open an issue or reach out via GitHub.
